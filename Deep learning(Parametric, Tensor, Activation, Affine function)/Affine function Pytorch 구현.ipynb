{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine function Pytorch 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x의 input values를 matrix형태로 들어가야한다.\n",
    "- x를 matrix형태로 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch values:tensor([[1.]]), Torch shape: torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[1.]])\n",
    "print(f'Torch values:{X}, Torch shape: {X.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W 도 X와 연산할 수 있게 Length of input를 맞추자. \n",
    "- b는 bias이기때문에 마지막에 더해주면된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: tensor([2.]), Weight size: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "W = torch.Tensor([2.])\n",
    "print(f'Weight: {W}, Weight size: {W.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "B =  0\n",
    "F = torch.matmul(X,W) + B # F(x;W,B) =  X*W + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine function + Activation function Forward 구현해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부17.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X value: tensor([[1., 2.]]), X shape: torch.Size([1, 2])\n",
      "Affine function Weight tensor([[-0.0861, -0.0767]])\n",
      "Affine function Bias: tensor([0.1479])\n",
      "========== matrx연산 ==========\n",
      "Weight shape: torch.Size([1, 2])\n",
      "Transforms Weight: tensor([[-0.0861],\n",
      "        [-0.0767]]), shape: torch.Size([2, 1])\n",
      "==================================================\n",
      "Dense layer 통과후 결과 값: tensor([[-0.0916]], grad_fn=<AddmmBackward>)\n",
      "Dense layer에서 weight 와 bise 추출후 Weight Transforms진행 후 행렬 연산 했을 때: tensor([[-0.0916]])\n"
     ]
    }
   ],
   "source": [
    "# Matrx X data 만들기\n",
    "X = torch.Tensor([[1., 2.]]) \n",
    "# X data shape 보기\n",
    "print(f'X value: {X}, X shape: {X.size()}')\n",
    "# Dense layer 만들기 Weight 와 bias \n",
    "# X shape는 1 x 2 그래서 Weight shape 2 x 1형태여야함 \n",
    "dense = nn.Linear(2, 1)\n",
    "Weight = dense.weight.data\n",
    "Bias = dense.bias.data\n",
    "result = dense(X)\n",
    "print(F'Affine function Weight {Weight}\\nAffine function Bias: {Bias}')\n",
    "# 실제 행렬 연산을 하여 dense layer 통과후 같은 값이 나오는지 확인\n",
    "print('='*10, 'matrx연산', '='*10)\n",
    "\n",
    "\n",
    "# Matrix_cal = torch.matmul(X, Weight) + Bias\n",
    "\n",
    "# mat1 and mat2 shapes cannot be multiplied (1x2 and 1x2) \n",
    "# Matrix_cal를 해주면 error가 나온다 왜일까? 현재 weight shape를 보자.\n",
    "print(f'Weight shape: {Weight.shape}') # 1 x 2이다  행렬 연산을 할 수 없다. 그래서 Transforms를 해줘야한다. \n",
    "Weight_T = Weight.view(2,1)\n",
    "print(f'Transforms Weight: {Weight_T}, shape: {Weight_T.shape}')\n",
    "\n",
    "Matrix_cal = torch.matmul(X, Weight_T) + Bias \n",
    "print('='*50)\n",
    "\n",
    "print(f'Dense layer 통과후 결과 값: {result}')\n",
    "print(f'Dense layer에서 weight 와 bise 추출후 Weight Transforms진행 후 행렬 연산 했을 때: {Matrix_cal}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X data를 uniform하게 샘플링 후 똑같이 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data: tensor([[-0.4639, -0.8518,  1.3930,  0.9631,  0.2068, -0.0806, -2.3068, -1.1601,\n",
      "         -0.9229, -0.9857]])\n",
      "X_data shape: torch.Size([1, 10])\n",
      "\n",
      "Weight data: tensor([[ 0.0905,  0.0234,  0.0814,  0.2055,  0.1649, -0.0745,  0.0158,  0.0546,\n",
      "         -0.1001, -0.0147]])\n",
      "Bias data: tensor([0.1486])\n",
      "\n",
      "\n",
      "Result 값:  tensor([[0.4451]], grad_fn=<AddmmBackward>)\n",
      "행렬 연산 값:  tensor([[0.4451]])\n"
     ]
    }
   ],
   "source": [
    "X_data = torch.randn((1,10))\n",
    "print(f'X_data: {X_data}')\n",
    "print(f'X_data shape: {X_data.size()}')\n",
    "Dense_layer= nn.Linear(10, 1)\n",
    "print()\n",
    "Weight = Dense_layer.weight.data\n",
    "Bias = Dense_layer.bias.data\n",
    "print(f'Weight data: {Weight}')\n",
    "print(f'Bias data: {Bias}')\n",
    "print()\n",
    "result = Dense_layer(X_data)\n",
    "print()\n",
    "\n",
    "#행렬 연산으로 같은 값 나왔는지 확인\n",
    "\n",
    "#Weight Transforms 시도\n",
    "Weight_TT = Weight.view(10, 1)\n",
    "print('Result 값: ', result)\n",
    "print('행렬 연산 값: ', torch.matmul(X_data, Weight_TT) + Bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Weight와 bias 내가 원하는 값으로 넣고 layer 통과 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30.]], grad_fn=<AddmmBackward>)\n",
      "result value:tensor([[30.]], grad_fn=<AddmmBackward>)\n",
      "prediction value: tensor([[30.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[1.]])\n",
    "\n",
    "dense = nn.Linear(1, 1)\n",
    "Weights = torch.nn.init.constant_(dense.weight, 10)\n",
    "bias_v = torch.nn.init.constant_(dense.bias, 20)\n",
    "y_y = dense(X)\n",
    "\n",
    "\n",
    "# 설정한 값 \n",
    "\n",
    "setting_weight = dense.weight.data\n",
    "setting_bias = dense.bias.data\n",
    "\n",
    "\n",
    "# 결과값 같은지 확인\n",
    "print(y_y)\n",
    "result_2 = torch.matmul(X,setting_weight)+setting_bias\n",
    "print(f'result value:{y_y}')\n",
    "print(f'prediction value: {result_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-결론 이렇게 X_data가 입력으로 들어오면 x_data 와 weight 끼리 Weight sum을 하게되고 여기서 나온 값에서 Activation function을 통과하게 되면 calar값이 나오게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
