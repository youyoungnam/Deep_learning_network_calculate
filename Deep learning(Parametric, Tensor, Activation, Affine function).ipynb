{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부1.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parametric function은 쉽게 말하자면, 함수가 parameter 값을 가지고 있다고 생각을 하면된다. 그래서 f(x;,θ) 식을 보면 x가 델타를 가지고 있다고 생각하면된다. 예를들어 input data를 1로 넣어주면 1 + θ가 나오고 θ에 따라 output 결과가 달라질 수 있음을 볼 수 있다. \n",
    "- Parametric function은 output 어떠한 결과를 을 만들어 낼 수 있는 변수를 가지고 있는 함수가 바로 Parametric function이다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공부시간에 따른 수학성적 변화 모델이 있다고 가정하자. 이때 x축이 공부시간이고 y축이 수학성적이다. 공부시간이 늘어날 수 록 수학성적은 올라간다. 그래서 공부시간에 따른 수학성적의 변화 모델이 어떻게 생겼냐면 y = ax + b  == f(x;a,b)처럼 생겼다. 즉, 이 함수가 Parametric function인걸 볼 수 있는데 아무리 공부시간을 크게 잡아도 a 와 b가 작다면, 예측결과는 달라질 수 있다. \n",
    "\n",
    "- 이 예시만 봐도 a와 b값에 변화에 따라 output의 결과가 달라지는걸 볼 수 있으므로, 이것이 Parametric function이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric function의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parametric function이 가지고있는 parameter에 따라 output이 달라질 수 있다. 즉, output를 만들어내는 자체가 달라질 수 있다.\n",
    "- 예로, linear regression에서 실제 정답값과 예측값의 차이를 가장 작게 만드는 Weight Bias가 무엇인지에 따라 output의 결과가 달라질 수 있다는것을 알 수 있다. 이것또한 Parametric function이라고 생각하면될거 같다.즉 linear regression에서 들어가있는 W, B parameter을 어떻게 조절하느냐가 바로 Parameric function이다.\n",
    "- 딥러닝은 Parameter를 가지고 있는 function들이 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchy of Tensor Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector, sclar, metric을 일반화 시킨게 Tensor다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero - order  Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zeroth-order Tensor은 0차원 즉 scalar값이다. 두개의 scalar 값이 다른 scalar값을 만들어 낼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R 표시는 집합에서 다루는 cartesian product 라는 것이다.\n",
    "- 예를들어 집합 B는 {0,1}있다고 가정하자. 집합 B x B 로 cartesian product를 만들어보면 B = {(0,0), (0,1), (1,0), (1,1)}를 만들어 낼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래서 가능한 모든것들을 포함시키는걸 catesian product라고 생각하면된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10과 20은 R x R에 catesian product에 포함이되고, a 와 b를 더해 30이 나오는걸 볼 수 있다.30도 R에 포함되는걸 볼 수 있다.\n",
    "- 그래서 scalar add scalar은 다른 scalar를 뽑을 수 있는것이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-order Tensor Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리가 흔히 알고있는 vector라고 생각하면된다.\n",
    "- 1차원\n",
    "- 사칙연산가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sclar 곱하기 vector은 다른 vector가 나오는걸 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadamard product(아다마르 곱)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 원소의 값끼리 곱하는게 아다마르 곱이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner product dot product 내적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 vector를 받아서 scalar값을 뽑아낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-order Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 고차원 Tensor의 표현과 연산 방법이다 우리가 흔히 알고있는 이미지를 예를들 수 있다. 28 x 28 x 3(RGB)채널"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zero-order operation ---- Third-order Operation까지 연결되는게  계측적 즉, 하이어라키가 존재하는걸 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 보통 수학에서 vector를 표현할 때 column vector형태로 표현이된다. 하지만 머신러닝에서는 raw wise vector로 표현되어야 하기때문에 Transforms를 시켜줘야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet(X data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1, 2, 3 ,. ..n의 의미는 각 행에 가지고있는 데이터들의 정보이다. 예를들어서 x1T로 예를들자면, 앤디학생이 가지고 있는 정보들이다.\n",
    "- L_i의 의미는 Length of input 즉 column의 갯수이다. feature 수? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pytohn image](공부12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 행이 여러개를 모아보면 행렬(metrix)이 되는걸 볼 수 있다.\n",
    "- 머신러닝에서 데이터의 표현을 metrix형태로 학습이 되는걸 알 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine Function with one Feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W: Weight Weight는 가중치이다. 가중치의 역할은 어떠한 데이터를 받았을 때 그 데이터를 몇배만큼 띄워줄건지 아니면 감소시킬건지 결정을 할 수 있는 애다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 보통은 머신러닝에서 input이 하나만들어 가는 경우는 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Affine Transformation은 어떤 input값 x가 들어왔을 때 weight를 곱하고 bias를 더해준게 Affine Transformation이다.\n",
    "- 표현방법으로는 F(x;, W,B) = x*W + B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Affine Transformation input으로 들어가는 형태를 보면 x가 sclar형태 인걸 볼 수 있고 output도 sclar형태로 나오는걸 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사실상 머신러닝에서 input으로 들어가는 데이터 형태는 이러한 형태이다. 여러개의 x값이 들어가고 x 개수만큼 weight도 같은 개수로 들어간다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사실 weight sum에 역할은 어떠한 data가 들어왔을 때 그 데이터가 얼마나 중요한지 안중요한지 판별할 때 weight로 판별하기 위해서다. \n",
    "- 그래서 예로들면 수학성적을 예측하고싶다. 그래서 수학성적을 잘 예측을 하려면 어떤 feature에 더 많은 가중치를 줘야하냐면 수학공부시간에 더 주면된다. 용돈보단 수학공부에 더 많은 가중치를 주면된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weight는 어떠한 데이터가 얼마나 중요한지 선언 해줄지에 대한 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine function with N features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X 데이터에해 Transforms를 해주고 Weight를 곱해주자. ----> Dot product연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 잠깐 언급한적이 있는데 Weighted sum에다가 bias를 더해주면 그게 Affine Transformation이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sigmoid \n",
    "- Tanh\n",
    "- Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine function + Activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Li: length of input \n",
    "- w: weight \n",
    "- b: bias\n",
    "- x: input data \n",
    "- a: activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W, B를 가진 Parametric function이 있고 이 함수에 X라는 row wise data가 input으로 들어간다. 그렇게  Transforms된 X는 Weight와 연산이 되고 연산된 값은 z라는 sclar값이 나오게 되고 z값은 activation function을 통과하여 a라는 결과값이 나오게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v에는 parametric function에서 나온결과 값이 activation function에 통과되 한번에 Activation 에 통과된 값이 한번에 처리되는걸 볼 수있다. 이 전체가 인공 뉴런이라고 생각하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini batch 연산과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mini batch연산 방법은 머신러닝 모델에 들어가 학습되는 데이터를 정할 수 있다. 예를들어 데이터를 100개씩 학습시키면 input data가 100개 들어가게 되고 한번에 output이 100개가 나온다. \n",
    "- 여기서 가장 중요한점이 있는데 mini batch를 한다고 해서 Weight값이랑 bias값이 변하지 않는다는걸 이미지처럼 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini batch metrix연산\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image](공부20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 행마다 mini batch 연산과 metrix mini batch의 연산의 차이점은 각각 데이터를 들어가는게 아니라 metrix형태로 들어가기 때문에 더 연산에 특화 될 수 있다. 예를들면 mini batch를 32로 지정했다고 가정하자. 그렇다면 32개의 각 행들을 하나의 metrix형태로 만들어 연산이 된다는 것 \n",
    "- 이렇게 하게 된다면, metrix가 연산이 더 효율적이고 gpu가 더 병렬연산에 특화되어 있어서 더 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
